{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31836d66-374e-4258-a9be-8bd40d67bcb8",
   "metadata": {},
   "source": [
    "#### 02 â€“ GCP Connectivity & Data Ingestion\n",
    "> **Phase:** Research & Development (R&D)  \n",
    "> **Source:** Local Staging (../data/)   \n",
    "> **Destination:** Google Cloud Storage (GCS) & BigQuery\n",
    "---\n",
    "**Goal:**  \n",
    "> Validate cloud infrastructure and automate the ingestion of raw data into the Google Cloud ecosystem.\n",
    "* **Auth:** Verify Application Default Credentials (ADC) and Service Account permissions.\n",
    "* **GCS (Bronze):** Upload the local raw Parquet file to the cloud storage bucket.\n",
    "* **BigQuery (Silver):** Create an External Table to query GCS Parquet files directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da85522-cc2b-4920-be83-2c53bb877e5a",
   "metadata": {},
   "source": [
    "#### Setup & Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa449408-771c-498d-8f05-09688ccc2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage, bigquery\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f448bf-f6f5-446d-bc1b-4f4bdbf99f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the project root \n",
    "root_path = Path.cwd().parent if 'notebooks' in os.getcwd() else Path.cwd()\n",
    "load_dotenv(dotenv_path=root_path / \".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e1010-ce65-41b7-9826-bcfc62768139",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv('GCP_PROJECT_ID')\n",
    "bucket_name = os.getenv('GCP_GCS_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c8618-a305-4939-962b-af80575ad202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectivity test\n",
    "try:\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bq_client = bigquery.Client(project=project_id)\n",
    "    print(f\"Auth Success: Using Application Default Credentials (ADC)\")\n",
    "except Exception as e:\n",
    "    print(f\"Auth Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e1067-3a27-4608-99e9-3c895d5886a8",
   "metadata": {},
   "source": [
    "#### GCS Ingestion (Bronze Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f8131-69c5-411d-9eab-aefad136cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gcs(bucket_name, source_file_path, destination_blob_name):\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    file_size = os.path.getsize(source_file_path)\n",
    "    \n",
    "    print(f\"Uploading to gs://{bucket_name}/{destination_blob_name}...\")\n",
    "    with tqdm(total=file_size, unit='B', unit_scale=True, desc=\"Progress\") as pbar:\n",
    "        blob.upload_from_filename(source_file_path)\n",
    "        pbar.update(file_size)\n",
    "    print(f\"Upload Complete.\")\n",
    "\n",
    "local_file = root_path / 'data' / 'green_tripdata_2025-11.parquet'\n",
    "gcs_destination = 'bronze/green_taxi_2025_11.parquet'\n",
    "\n",
    "upload_to_gcs(bucket_name, str(local_file), gcs_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724bb024-aef8-4b7f-905a-4c13d73e8c8a",
   "metadata": {},
   "source": [
    "#### BigQuery Staging (Silver Layer)\n",
    "Register the external data and load the lookup dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab25a54-c61a-4456-9906-d9537be7f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create external table for taxi trips\n",
    "table_id = f\"{project_id}.trips_data_silver.ext_green_taxi\"\n",
    "external_config = bigquery.ExternalConfig(\"PARQUET\")\n",
    "external_config.source_uris = [f\"gs://{bucket_name}/{gcs_destination}\"]\n",
    "\n",
    "table = bigquery.Table(table_id)\n",
    "table.external_data_configuration = external_config\n",
    "\n",
    "try:\n",
    "    bq_client.create_table(table, exists_ok=True)\n",
    "    print(f\"External Table registered: {table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"BigQuery Table creation failed: {e}\")\n",
    "\n",
    "# load native zones table \n",
    "zones_path = root_path / 'data' / 'taxi_zone_lookup.csv'\n",
    "df_zones = pd.read_csv(zones_path)\n",
    "table_fq = f\"{project_id}.trips_data_silver.zones\"\n",
    "\n",
    "try:\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job = bq_client.load_table_from_dataframe(df_zones, table_fq, job_config=job_config)\n",
    "    job.result() \n",
    "    print(f\"Dimension Table 'zones' loaded to BigQuery: {table_fq}\")\n",
    "except Exception as e:\n",
    "    print(f\"Zones load failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17900a-1445-4529-9045-248d7b6aed72",
   "metadata": {},
   "source": [
    "#### Infrastructure Validation\n",
    "Run a quick SQL query to ensure the schema was mapped correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2f450-0cf0-461a-b565-be844bcd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check: join tables to prove infra is fully functional\n",
    "sql = f\"\"\"\n",
    "    SELECT \n",
    "        t.vendorid, \n",
    "        t.lpep_pickup_datetime, \n",
    "        z.Zone \n",
    "    FROM `{table_id}` t\n",
    "    JOIN `{table_fq}` z ON t.PULocationID = z.LocationID\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "try:\n",
    "    df_val = bq_client.query(sql).to_dataframe()\n",
    "    print(\"Sample Joined Data:\")\n",
    "    display(df_val)\n",
    "    print(\"Infrastructure Validated. Staging Layer is ready for Analytics.\")\n",
    "except Exception as e:\n",
    "    print(f\"Validation Query failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
